#!/usr/bin/env python3
"""ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ãƒ»ç•°å¸¸æ¤œçŸ¥ãƒ»LLMè§£æã®ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ.

ä½¿ã„æ–¹:
    python main.py [--detailed]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --detailed  ç•°å¸¸ãŒãªãã¦ã‚‚è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã—ã¦LLMè§£æã‚’å®Ÿè¡Œ
"""

import json
import logging
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any

from anomaly_detector import AnomalyDetector
from config import validate_config
from llm_analyzer import analyze_metrics_sync
from metrics_queries import DETAILED_QUERIES, SUMMARY_QUERIES
from prometheus_client import PrometheusClient
from utils import format_bytes, format_percentage, format_rate

logger = logging.getLogger(__name__)


def save_result(data: dict[str, Any], filename: str) -> Path | None:
    """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜."""
    try:
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)

        filepath = output_dir / filename
        with filepath.open("w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        logger.info("çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: %s", filepath)
    except OSError:
        logger.exception("ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None
    else:
        return filepath


def format_summary(summary: dict[str, Any]) -> str:
    """ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ."""
    lines = ["=" * 60, "ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒª", "=" * 60]

    # è¦³æ¸¬å¥å…¨æ€§
    lines.append("\nã€è¦³æ¸¬å¥å…¨æ€§ã€‘")
    lines.append(f"  up: {summary.get('up', 'N/A')}")
    scrape_dur = summary.get("scrape_duration")
    lines.append(
        f"  scrape_duration: {scrape_dur:.3f}s"
        if scrape_dur
        else "  scrape_duration: N/A",
    )

    # CPU
    lines.append("\nã€CPUã€‘")
    lines.append(f"  ä½¿ç”¨ç‡: {format_percentage(summary.get('cpu_usage'))}")
    lines.append(f"  iowait: {format_percentage(summary.get('cpu_iowait'))}")
    lines.append(
        f"  load1: {summary.get('load1', 'N/A'):.2f}"
        if summary.get("load1")
        else "  load1: N/A",
    )
    lines.append(
        f"  load5: {summary.get('load5', 'N/A'):.2f}"
        if summary.get("load5")
        else "  load5: N/A",
    )
    lines.append(
        f"  load15: {summary.get('load15', 'N/A'):.2f}"
        if summary.get("load15")
        else "  load15: N/A",
    )

    # ãƒ¡ãƒ¢ãƒª
    lines.append("\nã€ãƒ¡ãƒ¢ãƒªã€‘")
    lines.append(f"  ä½¿ç”¨ç‡: {format_percentage(summary.get('memory_usage'))}")
    lines.append(f"  swap: {format_percentage(summary.get('swap_usage'))}")

    # ãƒ‡ã‚£ã‚¹ã‚¯
    lines.append("\nã€ãƒ‡ã‚£ã‚¹ã‚¯I/Oã€‘")
    lines.append(
        f"  èª­ã¿è¾¼ã¿: {format_bytes(summary.get('disk_read_bytes_per_sec'))}/s",
    )
    lines.append(
        f"  æ›¸ãè¾¼ã¿: {format_bytes(summary.get('disk_write_bytes_per_sec'))}/s",
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
    lines.append("\nã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã€‘")
    fs_top3 = summary.get("fs_usage_top3")
    if fs_top3 and isinstance(fs_top3, list):
        for i, fs in enumerate(fs_top3, 1):
            mp = fs.get("labels", {}).get("mountpoint", "unknown")
            val = fs.get("value", 0)
            lines.append(f"  {i}. {mp}: {val:.1f}%")
    else:
        lines.append("  ãƒ‡ãƒ¼ã‚¿ãªã—")

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    lines.append("\nã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã€‘")
    lines.append(f"  å—ä¿¡: {format_bytes(summary.get('network_rx_bytes_per_sec'))}/s")
    lines.append(f"  é€ä¿¡: {format_bytes(summary.get('network_tx_bytes_per_sec'))}/s")
    lines.append(f"  ã‚¨ãƒ©ãƒ¼: {format_rate(summary.get('network_err_per_sec', 0))}")

    # TCP
    lines.append("\nã€TCPã€‘")
    lines.append(f"  ç¢ºç«‹æ¸ˆã¿æ¥ç¶š: {summary.get('tcp_curr_estab', 'N/A')}")
    lines.append(f"  å†é€: {format_rate(summary.get('tcp_retrans_per_sec', 0))}")

    lines.append("=" * 60)
    return "\n".join(lines)


def main() -> int:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†."""
    # è¨­å®šã®æ¤œè¨¼
    if not validate_config():
        logger.error("è¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™")
        return 1

    timestamp = datetime.now(timezone(timedelta(hours=9))).strftime("%Y%m%d_%H%M%S")
    force_detailed = "--detailed" in sys.argv

    logger.info("\n%s", "=" * 60)
    logger.info("ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–ãƒ»ç•°å¸¸æ¤œçŸ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    logger.info(
        "å®Ÿè¡Œæ™‚åˆ»: %s",
        datetime.now(timezone(timedelta(hours=9))).strftime("%Y-%m-%d %H:%M:%S"),
    )
    logger.info("%s\n", "=" * 60)

    # 1. Prometheusã‹ã‚‰ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
    logger.info("ğŸ“Š ã‚µãƒãƒªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ä¸­...")
    try:
        prom_client = PrometheusClient()
        summary = prom_client.execute_queries(SUMMARY_QUERIES)
    except Exception:
        logger.exception("Prometheusã‹ã‚‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return 1

    logger.info("\n%s", format_summary(summary))

    # 2. ç•°å¸¸æ¤œçŸ¥
    logger.info("\nğŸ” ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œä¸­...")
    detector = AnomalyDetector()
    anomaly_result = detector.detect(summary)

    is_anomaly = anomaly_result["is_anomaly"]
    severity = anomaly_result["severity"]
    anomalies = anomaly_result["anomalies"]

    if is_anomaly:
        logger.warning(
            "\nâš ï¸  ç•°å¸¸ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸ (é‡è¦åº¦: %s, ä»¶æ•°: %dä»¶)",
            severity.upper(),
            len(anomalies),
        )
        for i, anomaly in enumerate(anomalies, 1):
            logger.warning(
                "  %d. [%s] %s",
                i,
                anomaly["severity"].upper(),
                anomaly["message"],
            )
    else:
        logger.info("\nâœ… ç•°å¸¸ã¯æ¤œçŸ¥ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

    # 3. è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—(ç•°å¸¸æ™‚ã¾ãŸã¯å¼·åˆ¶æŒ‡å®šæ™‚)
    detailed = None
    if is_anomaly or force_detailed:
        logger.info("\nğŸ“ˆ è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ä¸­...")
        detailed = prom_client.execute_queries(DETAILED_QUERIES)
        logger.info("âœ“ %då€‹ã®è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã—ã¾ã—ãŸ", len(detailed))
    # 4. LLMè§£æ
    logger.info("\nğŸ¤– LLMã§è§£æä¸­...")
    try:
        llm_result = analyze_metrics_sync(summary, anomaly_result, detailed)

        logger.info("\n%s", "=" * 60)
        logger.info("LLMè§£æçµæœ")
        logger.info("%s", "=" * 60)
        logger.info("%s", llm_result)
        logger.info("%s\n", "=" * 60)

    except Exception:
        logger.exception("LLMè§£æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        llm_result = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

    # 5. çµæœã‚’ä¿å­˜
    result_data = {
        "timestamp": datetime.now(timezone(timedelta(hours=9))).isoformat(),
        "summary": summary,
        "anomaly_detection": anomaly_result,
        "detailed_metrics": detailed,
        "llm_analysis": llm_result,
    }

    save_result(result_data, f"metrics_{timestamp}.json")

    # ç•°å¸¸æ™‚ã¯åˆ¥é€”ãƒ­ã‚°ã«ã‚‚è¨˜éŒ²
    if is_anomaly:
        anomaly_log = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "severity": severity,
            "anomalies": anomalies,
            "llm_analysis": llm_result,
        }
        save_result(anomaly_log, f"anomaly_{timestamp}.json")
        logger.warning("âš ï¸  ç•°å¸¸ãƒ­ã‚°ã‚‚ä¿å­˜ã—ã¾ã—ãŸ: output/anomaly_%s.json\n", timestamp)

    logger.info("âœ… å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ\n")

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰(ç•°å¸¸æ™‚ã¯1ã‚’è¿”ã™)
    return 1 if is_anomaly else 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
